{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "sns.set_style('whitegrid')\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error ,mean_squared_error,r2_score,max_error\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.neighbors import  KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import RandomForestRegressor,AdaBoostRegressor, GradientBoostingRegressor\n",
    "import xgboost\n",
    "import pickle\n",
    "pd.set_option('display.float_format', lambda x: '%.2f' % x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Leyendo los datos de trabajo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Marca</th>\n",
       "      <th>Modelo</th>\n",
       "      <th>Precio</th>\n",
       "      <th>Tipo_Combustible</th>\n",
       "      <th>Año</th>\n",
       "      <th>kms</th>\n",
       "      <th>CV</th>\n",
       "      <th>N_Puertas</th>\n",
       "      <th>Tipo_Cambio</th>\n",
       "      <th>color</th>\n",
       "      <th>N_Fotos</th>\n",
       "      <th>Provincia</th>\n",
       "      <th>TDG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>172</td>\n",
       "      <td>6200</td>\n",
       "      <td>4</td>\n",
       "      <td>2017.00</td>\n",
       "      <td>50071</td>\n",
       "      <td>82.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>42</td>\n",
       "      <td>-7.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>814</td>\n",
       "      <td>7851</td>\n",
       "      <td>3</td>\n",
       "      <td>2016.00</td>\n",
       "      <td>103000</td>\n",
       "      <td>100.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>-12.11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>221</td>\n",
       "      <td>19426</td>\n",
       "      <td>3</td>\n",
       "      <td>2014.00</td>\n",
       "      <td>120000</td>\n",
       "      <td>140.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>33</td>\n",
       "      <td>-5.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>813</td>\n",
       "      <td>22850</td>\n",
       "      <td>3</td>\n",
       "      <td>2017.00</td>\n",
       "      <td>107000</td>\n",
       "      <td>130.00</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>-3.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>40</td>\n",
       "      <td>11490</td>\n",
       "      <td>4</td>\n",
       "      <td>2016.00</td>\n",
       "      <td>78665</td>\n",
       "      <td>130.00</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>32</td>\n",
       "      <td>29</td>\n",
       "      <td>-5.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Marca  Modelo  Precio  Tipo_Combustible     Año     kms     CV  N_Puertas  \\\n",
       "0      1     172    6200                 4 2017.00   50071  82.00          2   \n",
       "1      1     814    7851                 3 2016.00  103000 100.00          2   \n",
       "2      1     221   19426                 3 2014.00  120000 140.00          2   \n",
       "3      1     813   22850                 3 2017.00  107000 130.00          3   \n",
       "4      1      40   11490                 4 2016.00   78665 130.00          2   \n",
       "\n",
       "   Tipo_Cambio  color  N_Fotos  Provincia    TDG  \n",
       "0            2      3        6         42  -7.06  \n",
       "1            2      3       10          7 -12.11  \n",
       "2            2      3        9         33  -5.17  \n",
       "3            2      3        4         39  -3.68  \n",
       "4            2      3       32         29  -5.83  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/processed/coches_segunda_mano_ML.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Divido el DF en train y test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Marca', 'Modelo', 'Precio', 'Tipo_Combustible', 'Año', 'kms', 'CV',\n",
       "       'N_Puertas', 'Tipo_Cambio', 'color', 'N_Fotos', 'Provincia', 'TDG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(41472, 12)\n",
      "(41472,)\n"
     ]
    }
   ],
   "source": [
    "X = df.drop(['Precio'],axis=1)\n",
    "y = df['Precio']\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(33177, 12)\n",
      "(8295, 12)\n",
      "(33177,)\n",
      "(8295,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(X_test.shape)\n",
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_mod = LinearRegression()\n",
    "reg_mod.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coeficient</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Marca</th>\n",
       "      <td>3834.156828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Año</th>\n",
       "      <td>804.062385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>320.375177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CV</th>\n",
       "      <td>144.537637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modelo</th>\n",
       "      <td>0.178467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kms</th>\n",
       "      <td>-0.063524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Provincia</th>\n",
       "      <td>-5.122451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Fotos</th>\n",
       "      <td>-17.274696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TDG</th>\n",
       "      <td>-56.529458</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tipo_Cambio</th>\n",
       "      <td>-73.138220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Puertas</th>\n",
       "      <td>-111.656186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tipo_Combustible</th>\n",
       "      <td>-1107.365687</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Coeficient\n",
       "Marca             3834.156828\n",
       "Año                804.062385\n",
       "color              320.375177\n",
       "CV                 144.537637\n",
       "Modelo               0.178467\n",
       "kms                 -0.063524\n",
       "Provincia           -5.122451\n",
       "N_Fotos            -17.274696\n",
       "TDG                -56.529458\n",
       "Tipo_Cambio        -73.138220\n",
       "N_Puertas         -111.656186\n",
       "Tipo_Combustible -1107.365687"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coef_reg_mod = pd.DataFrame(reg_mod.coef_,\n",
    "                            X.columns,\n",
    "                            columns=['Coeficient'])\n",
    "\n",
    "coef_reg_mod.sort_values('Coeficient', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = reg_mod.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  4585.698659119464\n",
      "MAPE:  54.0 %\n",
      "MSE:  83836711.89741418\n",
      "RMSE:  9156.238960261695\n",
      "R2_Score 0.6992203562833135\n"
     ]
    }
   ],
   "source": [
    "MAE = mean_absolute_error(y_train, predictions)\n",
    "MAPE = mean_absolute_percentage_error(y_train,predictions)\n",
    "MSE = mean_squared_error(y_train,predictions)\n",
    "RMSE = np.sqrt(mean_squared_error(y_train,predictions))\n",
    "RS_SCORE = r2_score(y_train,predictions)\n",
    "print(\"MAE: \", MAE)\n",
    "print(\"MAPE: \", MAPE.round(2)*100, \"%\")\n",
    "print(\"MSE: \", MSE)\n",
    "print(\"RMSE: \", RMSE)\n",
    "print(\"R2_Score\",RS_SCORE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 4768.59\n",
      "test MAPE: 53.0 %\n",
      "test MSE: 117283074.77\n",
      "Test RMSE:10829.7300\n",
      "RS_SCORE 0.67\n"
     ]
    }
   ],
   "source": [
    "print(\"test MAE:\", mean_absolute_error(y_test, reg_mod.predict(X_test)).round(2))\n",
    "print(\"test MAPE:\", mean_absolute_percentage_error(y_test, reg_mod.predict(X_test)).round(2)*100, \"%\")\n",
    "print(\"test MSE:\", mean_squared_error(y_test, reg_mod.predict(X_test)).round(2))\n",
    "print(\"Test RMSE:%0.4f\"% np.sqrt(mean_squared_error(y_test, reg_mod.predict(X_test))).round(2))\n",
    "print('RS_SCORE', r2_score(y_test,reg_mod.predict(X_test)).round(2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardo el modelo\n",
    "\n",
    "with open('modelos/otros/lr_model','wb') as archivo_salida:\n",
    "    pickle.dump(reg_mod,archivo_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Encontrando el mejor modelo con un Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LinearRegression(normalize=False)\n",
      "{'copy_X': True, 'fit_intercept': True, 'normalize': False}\n",
      "0.7006571174074228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "parameters = {'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True, False]}\n",
    "\n",
    "grid = GridSearchCV(reg_mod, parameters, cv=5)\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "print(grid.best_estimator_)\n",
    "print(grid.best_params_)\n",
    "print(grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor estimator es LinearRegression(normalize=False)\n",
      "Los mejores parámetros son {'copy_X': True, 'fit_intercept': True, 'normalize': False}\n",
      "El mejro score es 0.7006571174074228\n"
     ]
    }
   ],
   "source": [
    "print(\"El mejor estimator es\",grid.best_estimator_)\n",
    "print(\"Los mejores parámetros son\",grid.best_params_)\n",
    "print(\"El mejro score es\",grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg_mod_2 = LinearRegression(copy_X = True, fit_intercept= True, normalize=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LinearRegression(normalize=False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_mod_2.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_2 = reg_mod_2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20287.4699548 , 14381.74437541,  5758.32875141, ...,\n",
       "       22411.96677278,  -335.88075856,   810.56372142])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  4585.698659119464\n",
      "MAPE:  54.0 %\n",
      "MSE:  83836711.89741418\n",
      "RMSE:  9156.238960261695\n",
      "R2_Score 0.6992203562833135\n"
     ]
    }
   ],
   "source": [
    "MAE_2 = mean_absolute_error(y_train, predictions_2)\n",
    "MAPE_2 = mean_absolute_percentage_error(y_train,predictions_2)\n",
    "MSE_2 = mean_squared_error(y_train,predictions_2)\n",
    "RMSE_2 = np.sqrt(mean_squared_error(y_train,predictions_2))\n",
    "RS_SCORE_2 = r2_score(y_train,predictions_2)\n",
    "print(\"MAE: \", MAE_2)\n",
    "print(\"MAPE: \", MAPE_2.round(2)*100, \"%\")\n",
    "print(\"MSE: \", MSE_2)\n",
    "print(\"RMSE: \", RMSE_2)\n",
    "print(\"R2_Score\",RS_SCORE_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 4768.59\n",
      "test MAPE: 53.0 %\n",
      "test MSE: 117283074.77\n",
      "Test RMSE:10829.7300\n",
      "RS_SCORE 0.67\n"
     ]
    }
   ],
   "source": [
    "print(\"test MAE:\", mean_absolute_error(y_test, reg_mod_2.predict(X_test)).round(2))\n",
    "print(\"test MAPE:\", mean_absolute_percentage_error(y_test, reg_mod_2.predict(X_test)).round(2)*100, \"%\")\n",
    "print(\"test MSE:\", mean_squared_error(y_test, reg_mod_2.predict(X_test)).round(2))\n",
    "print(\"Test RMSE:%0.4f\"% np.sqrt(mean_squared_error(y_test, reg_mod_2.predict(X_test))).round(2))\n",
    "print('RS_SCORE', r2_score(y_test,reg_mod_2.predict(X_test)).round(2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>Prediction_GridSearch</th>\n",
       "      <th>Diferencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20287.469955</td>\n",
       "      <td>20287.469955</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14381.744375</td>\n",
       "      <td>14381.744375</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5758.328751</td>\n",
       "      <td>5758.328751</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20019.929463</td>\n",
       "      <td>20019.929463</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19278.324336</td>\n",
       "      <td>19278.324336</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33172</th>\n",
       "      <td>18919.702190</td>\n",
       "      <td>18919.702190</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33173</th>\n",
       "      <td>19743.983241</td>\n",
       "      <td>19743.983241</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33174</th>\n",
       "      <td>22411.966773</td>\n",
       "      <td>22411.966773</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33175</th>\n",
       "      <td>-335.880759</td>\n",
       "      <td>-335.880759</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33176</th>\n",
       "      <td>810.563721</td>\n",
       "      <td>810.563721</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33177 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         prediction  Prediction_GridSearch  Diferencia\n",
       "0      20287.469955           20287.469955         0.0\n",
       "1      14381.744375           14381.744375         0.0\n",
       "2       5758.328751            5758.328751         0.0\n",
       "3      20019.929463           20019.929463         0.0\n",
       "4      19278.324336           19278.324336         0.0\n",
       "...             ...                    ...         ...\n",
       "33172  18919.702190           18919.702190         0.0\n",
       "33173  19743.983241           19743.983241         0.0\n",
       "33174  22411.966773           22411.966773         0.0\n",
       "33175   -335.880759            -335.880759         0.0\n",
       "33176    810.563721             810.563721         0.0\n",
       "\n",
       "[33177 rows x 3 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparacion = pd.DataFrame(predictions, columns=['prediction'])\n",
    "comparacion['Prediction_GridSearch'] = predictions_2\n",
    "comparacion['Diferencia'] = abs(comparacion['prediction'] - comparacion['Prediction_GridSearch'])\n",
    "comparacion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Polynomial Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_reg = PolynomialFeatures(degree=4)\n",
    "poly_reg.fit(X_train)\n",
    "X_poly_train = poly_reg.transform(X_train) \n",
    "\n",
    "pol_reg = LinearRegression()\n",
    "pol_reg.fit(X_poly_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17574.02038854, 12502.6809426 ,  7464.80885143, ...,\n",
       "       18869.7840265 ,  4635.37571801, -1397.30565997])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_polynomial = pol_reg.predict(X_poly_train)\n",
    "predictions_polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  3452.8543868993956\n",
      "MAPE:  37.159355462057\n",
      "MSE:  46631811.17479712\n",
      "RMSE:  6828.748873314725\n",
      "R2_Score 0.8326997894647645\n"
     ]
    }
   ],
   "source": [
    "MAE_pol = mean_absolute_error(y_train, predictions_polynomial)\n",
    "MAPE_pol = mean_absolute_percentage_error(y_train,predictions_polynomial)\n",
    "MSE_pol = mean_squared_error(y_train,predictions_polynomial)\n",
    "RMSE_pol = np.sqrt(mean_squared_error(y_train,predictions_polynomial))\n",
    "RS_SCORE_pol = r2_score(y_train,predictions_polynomial)\n",
    "print(\"MAE: \", MAE_pol)\n",
    "print(\"MAPE: \",MAPE_pol*100)\n",
    "print(\"MSE: \", MSE_pol)\n",
    "print(\"RMSE: \", RMSE_pol)\n",
    "print(\"R2_Score\",RS_SCORE_pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_reg_test = PolynomialFeatures(degree=4)\n",
    "poly_reg_test.fit(X_train)\n",
    "X_poly_test = poly_reg.transform(X_test) \n",
    "\n",
    "pol_reg_test = LinearRegression()\n",
    "pol_reg_test.fit(X_poly_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 2987.31\n",
      "test MAPE: 35.0 %\n",
      "test MSE: 25979246.74\n",
      "Test RMSE:5096.9800\n",
      "RS_SCORE 0.93\n"
     ]
    }
   ],
   "source": [
    "print(\"test MAE:\", mean_absolute_error(y_test, pol_reg_test.predict(X_poly_test)).round(2))\n",
    "print(\"test MAPE:\", mean_absolute_percentage_error(y_test, pol_reg_test.predict(X_poly_test)).round(2)*100, \"%\")\n",
    "print(\"test MSE:\", mean_squared_error(y_test, pol_reg_test.predict(X_poly_test)).round(2))\n",
    "print(\"Test RMSE:%0.4f\"% np.sqrt(mean_squared_error(y_test, pol_reg_test.predict(X_poly_test))).round(2))\n",
    "print('RS_SCORE', r2_score(y_test,pol_reg_test.predict(X_poly_test)).round(2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardo el mejor modelo de polynomial\n",
    "\n",
    "with open('modelos/otros/polynomial_model','wb') as archivo_salida:\n",
    "    pickle.dump(pol_reg_test,archivo_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scorer=make_scorer(mean_squared_error, greater_is_better = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:145: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2.\n",
      "If you wish to scale the data, use Pipeline with a StandardScaler in a preprocessing stage. To reproduce the previous behavior:\n",
      "\n",
      "from sklearn.pipeline import make_pipeline\n",
      "\n",
      "model = make_pipeline(StandardScaler(with_mean=False), LinearRegression())\n",
      "\n",
      "If you wish to pass a sample_weight parameter, you need to pass it as a fit parameter to each step of the pipeline as follows:\n",
      "\n",
      "kwargs = {s[0] + '__sample_weight': sample_weight for s in model.steps}\n",
      "model.fit(X, y, **kwargs)\n",
      "\n",
      "\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n",
      "C:\\Users\\ejgar\\AppData\\Local\\Programs\\Python\\Python37\\lib\\site-packages\\sklearn\\linear_model\\_base.py:155: FutureWarning: 'normalize' was deprecated in version 1.0 and will be removed in 1.2. Please leave the normalize parameter to its default value to silence this warning. The default behavior of this estimator is to not do any normalization. If normalization is needed please use sklearn.preprocessing.StandardScaler instead.\n",
      "  FutureWarning,\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=LinearRegression(),\n",
       "             param_grid={'copy_X': [True, False],\n",
       "                         'fit_intercept': [True, False],\n",
       "                         'normalize': [True, False]},\n",
       "             scoring=make_scorer(mean_squared_error, greater_is_better=False))"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True, False],}\n",
    "grid_search1 = GridSearchCV(pol_reg, params, scoring=scorer)\n",
    "grid_search1.fit(X_poly_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor estimator es LinearRegression(normalize=False)\n",
      "Los mejores parámetros son {'copy_X': True, 'fit_intercept': True, 'normalize': False}\n",
      "El mejor score es -21568686313.90991\n"
     ]
    }
   ],
   "source": [
    "print(\"El mejor estimator es\",grid_search1.best_estimator_)\n",
    "print(\"Los mejores parámetros son\",grid_search1.best_params_)\n",
    "print(\"El mejor score es\",grid_search1.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17574.02038854, 12502.6809426 ,  7464.80885143, ...,\n",
       "       18869.7840265 ,  4635.37571801, -1397.30565997])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_pol_grid = grid_search1.predict(X_poly_train)\n",
    "predictions_pol_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  3452.8543868993956\n",
      "MAPE:  0.37159355462057003\n",
      "MSE:  46631811.17479712\n",
      "RMSE:  6828.748873314725\n",
      "R2_Score 0.8326997894647645\n"
     ]
    }
   ],
   "source": [
    "MAE_pol_grid = mean_absolute_error(y_train, predictions_pol_grid)\n",
    "MAPE_pol_grid = mean_absolute_percentage_error(y_train,predictions_pol_grid)\n",
    "MSE_pol_grid = mean_squared_error(y_train,predictions_pol_grid)\n",
    "RMSE_pol_grid = np.sqrt(mean_squared_error(y_train,predictions_pol_grid))\n",
    "RS_SCORE_pol_grid = r2_score(y_train,predictions_pol_grid)\n",
    "print(\"MAE: \", MAE_pol_grid)\n",
    "print(\"MAPE: \",MAPE_pol_grid)\n",
    "print(\"MSE: \", MSE_pol_grid)\n",
    "print(\"RMSE: \", RMSE_pol_grid)\n",
    "print(\"R2_Score\",RS_SCORE_pol_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>prediction</th>\n",
       "      <th>Prediction_GridSearch</th>\n",
       "      <th>Diferencia</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17574.020389</td>\n",
       "      <td>17574.020389</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12502.680943</td>\n",
       "      <td>12502.680943</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7464.808851</td>\n",
       "      <td>7464.808851</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22199.466171</td>\n",
       "      <td>22199.466171</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19013.212541</td>\n",
       "      <td>19013.212541</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33172</th>\n",
       "      <td>16447.399010</td>\n",
       "      <td>16447.399010</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33173</th>\n",
       "      <td>15357.387980</td>\n",
       "      <td>15357.387980</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33174</th>\n",
       "      <td>18869.784026</td>\n",
       "      <td>18869.784026</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33175</th>\n",
       "      <td>4635.375718</td>\n",
       "      <td>4635.375718</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33176</th>\n",
       "      <td>-1397.305660</td>\n",
       "      <td>-1397.305660</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>33177 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         prediction  Prediction_GridSearch  Diferencia\n",
       "0      17574.020389           17574.020389         0.0\n",
       "1      12502.680943           12502.680943         0.0\n",
       "2       7464.808851            7464.808851         0.0\n",
       "3      22199.466171           22199.466171         0.0\n",
       "4      19013.212541           19013.212541         0.0\n",
       "...             ...                    ...         ...\n",
       "33172  16447.399010           16447.399010         0.0\n",
       "33173  15357.387980           15357.387980         0.0\n",
       "33174  18869.784026           18869.784026         0.0\n",
       "33175   4635.375718            4635.375718         0.0\n",
       "33176  -1397.305660           -1397.305660         0.0\n",
       "\n",
       "[33177 rows x 3 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comparacion_pol = pd.DataFrame(predictions_polynomial, columns=['prediction'])\n",
    "comparacion_pol['Prediction_GridSearch'] = predictions_pol_grid\n",
    "comparacion_pol['Diferencia'] = abs(comparacion['prediction'] - comparacion['Prediction_GridSearch'])\n",
    "comparacion_pol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=5)"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr = DecisionTreeRegressor(max_depth=5)\n",
    "dtr.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8.17636265e-03, 1.59358035e-02, 0.00000000e+00, 4.66674150e-04,\n",
       "       5.44290915e-03, 5.68175715e-01, 0.00000000e+00, 0.00000000e+00,\n",
       "       0.00000000e+00, 0.00000000e+00, 0.00000000e+00, 4.01802536e-01])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Feature Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>CV</th>\n",
       "      <td>0.57</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TDG</th>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Modelo</th>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Marca</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kms</th>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Año</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tipo_Combustible</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Puertas</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tipo_Cambio</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>color</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>N_Fotos</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Provincia</th>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Feature Importance\n",
       "CV                              0.57\n",
       "TDG                             0.40\n",
       "Modelo                          0.02\n",
       "Marca                           0.01\n",
       "kms                             0.01\n",
       "Año                             0.00\n",
       "Tipo_Combustible                0.00\n",
       "N_Puertas                       0.00\n",
       "Tipo_Cambio                     0.00\n",
       "color                           0.00\n",
       "N_Fotos                         0.00\n",
       "Provincia                       0.00"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr_feature_importance = pd.DataFrame(dtr.feature_importances_,\n",
    "                            X_train.columns,\n",
    "                            columns=['Feature Importance'])\n",
    "\n",
    "dtr_feature_importance.sort_values('Feature Importance', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([26445.00532702, 12248.82144831,  8942.66402466, ...,\n",
       "       19744.47208644,  4068.58078778,  1966.27403846])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_dtr = dtr.predict(X_train)\n",
    "predictions_dtr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  3462.5845015072646\n",
      "MAPE:  0.23839335766876343\n",
      "MSE:  39714403.43513876\n",
      "RMSE:  6301.936482950202\n",
      "R2_Score 0.8575172636749102\n"
     ]
    }
   ],
   "source": [
    "MAE_dtr = mean_absolute_error(y_train, predictions_dtr)\n",
    "MAPE_dtr = mean_absolute_percentage_error(y_train,predictions_dtr)\n",
    "MSE_dtr = mean_squared_error(y_train,predictions_dtr)\n",
    "RMSE_dtr = np.sqrt(mean_squared_error(y_train,predictions_dtr))\n",
    "RS_SCORE_dtr = r2_score(y_train,predictions_dtr)\n",
    "print(\"MAE: \", MAE_dtr)\n",
    "print(\"MAPE: \",MAPE_dtr)\n",
    "print(\"MSE: \", MSE_dtr)\n",
    "print(\"RMSE: \", RMSE_dtr)\n",
    "print(\"R2_Score\",RS_SCORE_dtr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 3612.530244730324\n",
      "test MAPE: 0.24041511029530904\n",
      "test MSE: 50188914.90606719\n",
      "Test RMSE:7084.4135\n",
      "RS_SCORE 0.8587991222790399\n"
     ]
    }
   ],
   "source": [
    "print(\"test MAE:\", mean_absolute_error(y_test, dtr.predict(X_test)))\n",
    "print(\"test MAPE:\", mean_absolute_percentage_error(y_test, dtr.predict(X_test)))\n",
    "print(\"test MSE:\", mean_squared_error(y_test, dtr.predict(X_test)))\n",
    "print(\"Test RMSE:%0.4f\"% np.sqrt(mean_squared_error(y_test, dtr.predict(X_test))))\n",
    "print('RS_SCORE', r2_score(y_test,dtr.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscando el mejor modelo de Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeRegressor(),\n",
       "             param_grid={'max_depth': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'min_samples_leaf': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
       "                         'min_samples_split': [2, 3, 4, 5, 6, 7, 8, 9, 10]},\n",
       "             return_train_score=True, scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree = DecisionTreeRegressor()\n",
    "\n",
    "parameters = {'max_depth':[1,2,3,4,5,6,7,8,9,10],\n",
    "              'min_samples_split':[2,3,4,5,6,7,8,9,10],\n",
    "              'min_samples_leaf':[1,2,3,4,5,6,7,8,9,10]}\n",
    "\n",
    "grid_dtr = GridSearchCV(tree, parameters, cv=5, scoring='neg_mean_squared_error', return_train_score=True)\n",
    "\n",
    "grid_dtr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor estimator es LinearRegression(normalize=False)\n",
      "Los mejores parámetros son {'copy_X': True, 'fit_intercept': True, 'normalize': False}\n",
      "El mejor score es 0.7006571174074228\n"
     ]
    }
   ],
   "source": [
    "print(\"El mejor estimator es\",grid.best_estimator_)\n",
    "print(\"Los mejores parámetros son\",grid.best_params_)\n",
    "print(\"El mejor score es\",grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Marca', 'Modelo', 'Tipo_Combustible', 'Año', 'kms', 'CV', 'N_Puertas',\n",
       "       'Tipo_Cambio', 'color', 'N_Fotos', 'Provincia', 'TDG'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([20503.08852459, 13460.99456522,  8848.64583333, ...,\n",
       "       19221.43508772,  5131.81081081,  1191.68604651])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_dtr_gs = grid_dtr.predict(X_train)\n",
    "predictions_dtr_gs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train:  1679.8\n",
      "MAPE train:  9.0 %\n",
      "MSE train:  16999273.71\n",
      "RMSE train:  4123.02\n",
      "R2_Score train 0.94\n"
     ]
    }
   ],
   "source": [
    "MAE_dtr_gs = mean_absolute_error(y_train, predictions_dtr_gs)\n",
    "MAPE_dtr_gs = mean_absolute_percentage_error(y_train,predictions_dtr_gs)\n",
    "MSE_dtr_gs = mean_squared_error(y_train,predictions_dtr_gs)\n",
    "RMSE_dtr_gs = np.sqrt(mean_squared_error(y_train,predictions_dtr_gs))\n",
    "RS_SCORE_dtr_gs = r2_score(y_train,predictions_dtr_gs)\n",
    "print(\"MAE train: \", MAE_dtr_gs.round(2))\n",
    "print(\"MAPE train: \",MAPE_dtr_gs.round(2)*100,\"%\")\n",
    "print(\"MSE train: \", MSE_dtr_gs.round(2))\n",
    "print(\"RMSE train: \", RMSE_dtr_gs.round(2))\n",
    "print(\"R2_Score train\",RS_SCORE_dtr_gs.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 1979.23\n",
      "test MAPE: 10.0 %\n",
      "test MSE: 35102027.57\n",
      "Test RMSE:5924.7000\n",
      "RS_SCORE 0.9\n"
     ]
    }
   ],
   "source": [
    "print(\"test MAE:\", mean_absolute_error(y_test, grid_dtr.predict(X_test)).round(2))\n",
    "print(\"test MAPE:\", mean_absolute_percentage_error(y_test, grid_dtr.predict(X_test)).round(2)*100, \"%\")\n",
    "print(\"test MSE:\", mean_squared_error(y_test, grid_dtr.predict(X_test)).round(2))\n",
    "print(\"Test RMSE:%0.4f\"% np.sqrt(mean_squared_error(y_test, grid_dtr.predict(X_test))).round(2))\n",
    "print('RS_SCORE', r2_score(y_test,grid_dtr.predict(X_test)).round(2))                                                                                                                                                                                                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardo el mejor modelo de Decision Tree\n",
    "\n",
    "with open('modelos/otros/DecissionTree_GridSearch_model','wb') as archivo_salida:\n",
    "    pickle.dump(grid_dtr,archivo_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scal = scaler.fit_transform(X_train) \n",
    "X_test_scal= scaler.transform(X_test)\n",
    "\n",
    "# Probé primero Min Max scaler, pero obtuve peores resultados. Así que me quedo con StandarScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor()"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "knn = KNeighborsRegressor(n_neighbors=5)\n",
    "knn.fit(X_train_scal,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_knn = knn.predict(X_train_scal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train:  2575.62\n",
      "MAPE train:  16.0 %\n",
      "MSE train:  32216325.75\n",
      "RMSE train:  5675.94\n",
      "R2_Score train 0.88\n"
     ]
    }
   ],
   "source": [
    "MAE_knn = mean_absolute_error(y_train, predictions_knn)\n",
    "MAPE_knn = mean_absolute_percentage_error(y_train,predictions_knn)\n",
    "MSE_knn = mean_squared_error(y_train,predictions_knn)\n",
    "RMSE_knn = np.sqrt(mean_squared_error(y_train,predictions_knn))\n",
    "RS_SCORE_knn = r2_score(y_train,predictions_knn)\n",
    "print(\"MAE train: \", MAE_knn.round(2))\n",
    "print(\"MAPE train: \",MAPE_knn.round(2)*100,\"%\")\n",
    "print(\"MSE train: \", MSE_knn.round(2))\n",
    "print(\"RMSE train: \", RMSE_knn.round(2))\n",
    "print(\"R2_Score train\",RS_SCORE_knn.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 3236.03\n",
      "test MAPE: 19.0 %\n",
      "test MSE: 55980274.91\n",
      "Test RMSE:7482.0000\n",
      "RS_SCORE 0.84\n"
     ]
    }
   ],
   "source": [
    "print(\"test MAE:\", mean_absolute_error(y_test, knn.predict(X_test_scal)).round(2))\n",
    "print(\"test MAPE:\", mean_absolute_percentage_error(y_test, knn.predict(X_test_scal)).round(2)*100, \"%\")\n",
    "print(\"test MSE:\", mean_squared_error(y_test, knn.predict(X_test_scal)).round(2))\n",
    "print(\"Test RMSE:%0.4f\"% np.sqrt(mean_squared_error(y_test, knn.predict(X_test_scal))).round(2))\n",
    "print('RS_SCORE', r2_score(y_test,knn.predict(X_test_scal)).round(2))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardo el mejor modelo de KNN\n",
    "\n",
    "with open('modelos/otros/KNN_model','wb') as archivo_salida:\n",
    "    pickle.dump(knn,archivo_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscando el mejor KNN con Gridsearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=KNeighborsRegressor(),\n",
       "             param_grid={'n_neighbors': array([1, 2, 3, 4, 5, 6, 7, 8, 9]),\n",
       "                         'weights': ['uniform', 'distance']})"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\"n_neighbors\": np.arange(1, 10), \n",
    "          \"weights\": [\"uniform\", \"distance\"]}\n",
    "\n",
    "grid_search_cv_knn = GridSearchCV(knn, params)\n",
    "grid_search_cv_knn.fit(X_train_scal, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor estimator es KNeighborsRegressor(n_neighbors=9, weights='distance')\n",
      "Los mejores parámetros son {'n_neighbors': 9, 'weights': 'distance'}\n",
      "El mejor score es 0.8358707950007268\n"
     ]
    }
   ],
   "source": [
    "print(\"El mejor estimator es\",grid_search_cv_knn.best_estimator_)\n",
    "print(\"Los mejores parámetros son\",grid_search_cv_knn.best_params_)\n",
    "print(\"El mejor score es\",grid_search_cv_knn.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_gs = KNeighborsRegressor(n_neighbors=7,weights='uniform',leaf_size=50,n_jobs=-1)\n",
    "knn_gs.fit(X_train_scal,y_train)\n",
    "predictions_knn_gs = knn_gs.predict(X_train_scal)\n",
    "# Con los parámetros que me da el gridsearch obtengo un modelo con overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train:  2739.8\n",
      "MAPE train:  17.0 %\n",
      "MSE train:  36515164.64\n",
      "RMSE train:  6042.78\n",
      "R2_Score train 0.87\n"
     ]
    }
   ],
   "source": [
    "MAE_knn_gs = mean_absolute_error(y_train, predictions_knn_gs)\n",
    "MAPE_knn_gs = mean_absolute_percentage_error(y_train,predictions_knn_gs)\n",
    "MSE_knn_gs = mean_squared_error(y_train,predictions_knn_gs)\n",
    "RMSE_knn_gs = np.sqrt(mean_squared_error(y_train,predictions_knn_gs))\n",
    "RS_SCORE_knn_gs = r2_score(y_train,predictions_knn_gs)\n",
    "print(\"MAE train: \", MAE_knn_gs.round(2))\n",
    "print(\"MAPE train: \",MAPE_knn_gs.round(2)*100,\"%\")\n",
    "print(\"MSE train: \", MSE_knn_gs.round(2))\n",
    "print(\"RMSE train: \", RMSE_knn_gs.round(2))\n",
    "print(\"R2_Score train\",RS_SCORE_knn_gs.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 3230.53\n",
      "test MAPE: 19.0 %\n",
      "test MSE: 53882272.34\n",
      "Test RMSE:7340.4500\n",
      "RS_SCORE 0.85\n"
     ]
    }
   ],
   "source": [
    "print(\"test MAE:\", mean_absolute_error(y_test, knn_gs.predict(X_test_scal)).round(2))\n",
    "print(\"test MAPE:\", mean_absolute_percentage_error(y_test, knn_gs.predict(X_test_scal)).round(2)*100, \"%\")\n",
    "print(\"test MSE:\", mean_squared_error(y_test, knn_gs.predict(X_test_scal)).round(2))\n",
    "print(\"Test RMSE:%0.4f\"% np.sqrt(mean_squared_error(y_test, knn_gs.predict(X_test_scal))).round(2))\n",
    "print('RS_SCORE', r2_score(y_test,knn_gs.predict(X_test_scal)).round(2))   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scal = scaler.fit_transform(X_train) \n",
    "X_test_scal= scaler.transform(X_test)\n",
    "\n",
    "# Min max scaler descarto, me da peores resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm = SVR()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR()"
      ]
     },
     "execution_count": 203,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm.fit(X_train_scal,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_svm = svm.predict(X_train_scal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train:  8651.46\n",
      "MAPE train:  97.0 %\n",
      "MSE train:  268815638.02\n",
      "RMSE train:  16395.6\n",
      "R2_Score train 0.04\n"
     ]
    }
   ],
   "source": [
    "MAE_svm = mean_absolute_error(y_train, predictions_svm)\n",
    "MAPE_svm = mean_absolute_percentage_error(y_train,predictions_svm)\n",
    "MSE_svm = mean_squared_error(y_train,predictions_svm)\n",
    "RMSE_svm = np.sqrt(mean_squared_error(y_train,predictions_svm))\n",
    "RS_SCORE_svm = r2_score(y_train,predictions_svm)\n",
    "print(\"MAE train: \", MAE_svm.round(2))\n",
    "print(\"MAPE train: \",MAPE_svm.round(2)*100,\"%\")\n",
    "print(\"MSE train: \", MSE_svm.round(2))\n",
    "print(\"RMSE train: \", RMSE_svm.round(2))\n",
    "print(\"R2_Score train\",RS_SCORE_svm.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 8951.62\n",
      "test MAPE: 97.0 %\n",
      "test MSE: 348100364.87\n",
      "Test RMSE:18657.4500\n",
      "RS_SCORE 0.02\n"
     ]
    }
   ],
   "source": [
    "print(\"test MAE:\", mean_absolute_error(y_test, svm.predict(X_test_scal)).round(2))\n",
    "print(\"test MAPE:\", mean_absolute_percentage_error(y_test, svm.predict(X_test_scal)).round(2)*100, \"%\")\n",
    "print(\"test MSE:\", mean_squared_error(y_test, svm.predict(X_test_scal)).round(2))\n",
    "print(\"Test RMSE:%0.4f\"% np.sqrt(mean_squared_error(y_test, svm.predict(X_test_scal))).round(2))\n",
    "print('RS_SCORE', r2_score(y_test,svm.predict(X_test_scal)).round(2))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Buscando el mejor modelo SVM con Gridsearch CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=SVR(),\n",
       "             param_grid={'C': [1, 10], 'kernel': ('linear', 'rbf')})"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "clf = GridSearchCV(svm, parameters)\n",
    "clf.fit(X_train_scal, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor estimator es SVR(C=10, kernel='linear')\n",
      "Los mejores parámetros son {'C': 10, 'kernel': 'linear'}\n",
      "El mejor score es 0.6558663341177673\n"
     ]
    }
   ],
   "source": [
    "print(\"El mejor estimator es\",clf.best_estimator_)\n",
    "print(\"Los mejores parámetros son\",clf.best_params_)\n",
    "print(\"El mejor score es\",clf.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=10, kernel='linear')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svm_grid = SVR(C=10,kernel='linear')\n",
    "svm_grid.fit(X_train_scal,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_svm_grid = svm_grid.predict(X_train_scal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train:  4231.66\n",
      "MAPE train:  42.0 %\n",
      "MSE train:  96511993.05\n",
      "RMSE train:  9824.05\n",
      "R2_Score train 0.65\n"
     ]
    }
   ],
   "source": [
    "MAE_svm_grid = mean_absolute_error(y_train, predictions_svm_grid)\n",
    "MAPE_svm_grid = mean_absolute_percentage_error(y_train,predictions_svm_grid)\n",
    "MSE_svm_grid = mean_squared_error(y_train,predictions_svm_grid)\n",
    "RMSE_svm_grid = np.sqrt(mean_squared_error(y_train,predictions_svm_grid))\n",
    "RS_SCORE_svm_grid = r2_score(y_train,predictions_svm_grid)\n",
    "print(\"MAE train: \", MAE_svm_grid.round(2))\n",
    "print(\"MAPE train: \",MAPE_svm_grid.round(2)*100,\"%\")\n",
    "print(\"MSE train: \", MSE_svm_grid.round(2))\n",
    "print(\"RMSE train: \", RMSE_svm_grid.round(2))\n",
    "print(\"R2_Score train\",RS_SCORE_svm_grid.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 4458.96\n",
      "test MAPE: 41.0 %\n",
      "test MSE: 141716795.62\n",
      "Test RMSE:11904.4900\n",
      "RS_SCORE 0.6\n"
     ]
    }
   ],
   "source": [
    "print(\"test MAE:\", mean_absolute_error(y_test, svm_grid.predict(X_test_scal)).round(2))\n",
    "print(\"test MAPE:\", mean_absolute_percentage_error(y_test, svm_grid.predict(X_test_scal)).round(2)*100, \"%\")\n",
    "print(\"test MSE:\", mean_squared_error(y_test, svm_grid.predict(X_test_scal)).round(2))\n",
    "print(\"Test RMSE:%0.4f\"% np.sqrt(mean_squared_error(y_test, svm_grid.predict(X_test_scal))).round(2))\n",
    "print('RS_SCORE', r2_score(y_test,svm_grid.predict(X_test_scal)).round(2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardo el mejor modelo de SVM\n",
    "\n",
    "with open('modelos/otros/SVM_GridSearch_model','wb') as archivo_salida:\n",
    "    pickle.dump(svm_grid,archivo_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnd_reg = RandomForestRegressor(n_estimators=500,\n",
    "                                 max_leaf_nodes=16,\n",
    "                                 random_state=42)\n",
    "rnd_reg.fit(X_train, y_train)\n",
    "\n",
    "prections_rnd_reg = rnd_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train:  3609.72\n",
      "MAPE train:  35.0 %\n",
      "MSE train:  35116142.54\n",
      "RMSE train:  5925.89\n",
      "R2_Score train 0.87\n"
     ]
    }
   ],
   "source": [
    "MAE_rnd_reg = mean_absolute_error(y_train, prections_rnd_reg)\n",
    "MAPE_rnd_reg = mean_absolute_percentage_error(y_train,prections_rnd_reg)\n",
    "MSE_rnd_reg = mean_squared_error(y_train,prections_rnd_reg)\n",
    "RMSE_rnd_reg = np.sqrt(mean_squared_error(y_train,prections_rnd_reg))\n",
    "RS_SCORE_rnd_reg = r2_score(y_train,prections_rnd_reg)\n",
    "print(\"MAE train: \", MAE_rnd_reg.round(2))\n",
    "print(\"MAPE train: \",MAPE_rnd_reg.round(2)*100,\"%\")\n",
    "print(\"MSE train: \", MSE_rnd_reg.round(2))\n",
    "print(\"RMSE train: \", RMSE_rnd_reg.round(2))\n",
    "print(\"R2_Score train\",RS_SCORE_rnd_reg.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 3728.7\n",
      "test MAPE: 36.0 %\n",
      "test MSE: 47247957.27\n",
      "Test RMSE:6873.7100\n",
      "RS_SCORE 0.87\n"
     ]
    }
   ],
   "source": [
    "print(\"test MAE:\", mean_absolute_error(y_test, rnd_reg.predict(X_test)).round(2))\n",
    "print(\"test MAPE:\", mean_absolute_percentage_error(y_test, rnd_reg.predict(X_test)).round(2)*100, \"%\")\n",
    "print(\"test MSE:\", mean_squared_error(y_test, rnd_reg.predict(X_test)).round(2))\n",
    "print(\"Test RMSE:%0.4f\"% np.sqrt(mean_squared_error(y_test, rnd_reg.predict(X_test))).round(2))\n",
    "print('RS_SCORE', r2_score(y_test,rnd_reg.predict(X_test)).round(2))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestRegressor(),\n",
       "             param_grid={'max_depth': range(1, 10),\n",
       "                         'n_estimators': range(1, 10)},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_par = {'n_estimators': range(1,10,1),'max_depth':range(1,10,1)}\n",
    "modelo = RandomForestRegressor()\n",
    "grid = GridSearchCV(modelo, grid_par,scoring='r2',cv=5)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor estimator es RandomForestRegressor(max_depth=9, n_estimators=8)\n",
      "Los mejores parámetros son {'max_depth': 9, 'n_estimators': 8}\n",
      "El mejor score es 0.9202360297230919\n"
     ]
    }
   ],
   "source": [
    "print(\"El mejor estimator es\",grid.best_estimator_)\n",
    "print(\"Los mejores parámetros son\",grid.best_params_)\n",
    "print(\"El mejor score es\",grid.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(max_depth=9, n_estimators=8)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid = RandomForestRegressor(max_depth=9,n_estimators=8)\n",
    "grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "prections_rnd_reg_grid = grid.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train:  1442.25\n",
      "MAPE train:  8.0 %\n",
      "MSE train:  9156415.09\n",
      "RMSE train:  3025.96\n",
      "R2_Score train 0.97\n"
     ]
    }
   ],
   "source": [
    "MAE_rnd_reg_grid = mean_absolute_error(y_train, prections_rnd_reg_grid)\n",
    "MAPE_rnd_reg_grid = mean_absolute_percentage_error(y_train,prections_rnd_reg_grid)\n",
    "MSE_rnd_reg_grid = mean_squared_error(y_train,prections_rnd_reg_grid)\n",
    "RMSE_rnd_reg_grid = np.sqrt(mean_squared_error(y_train,prections_rnd_reg_grid))\n",
    "RS_SCORE_rnd_reg_grid = r2_score(y_train,prections_rnd_reg_grid)\n",
    "print(\"MAE train: \", MAE_rnd_reg_grid.round(2))\n",
    "print(\"MAPE train: \",MAPE_rnd_reg_grid.round(2)*100,\"%\")\n",
    "print(\"MSE train: \", MSE_rnd_reg_grid.round(2))\n",
    "print(\"RMSE train: \", RMSE_rnd_reg_grid.round(2))\n",
    "print(\"R2_Score train\",RS_SCORE_rnd_reg_grid.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 1690.11\n",
      "test MAPE: 9.0 %\n",
      "test MSE: 22447050.25\n",
      "Test RMSE:4737.8300\n",
      "RS_SCORE 0.94\n"
     ]
    }
   ],
   "source": [
    "print(\"test MAE:\", mean_absolute_error(y_test, grid.predict(X_test)).round(2))\n",
    "print(\"test MAPE:\", mean_absolute_percentage_error(y_test, grid.predict(X_test)).round(2)*100, \"%\")\n",
    "print(\"test MSE:\", mean_squared_error(y_test, grid.predict(X_test)).round(2))\n",
    "print(\"Test RMSE:%0.4f\"% np.sqrt(mean_squared_error(y_test, grid.predict(X_test))).round(2))\n",
    "print('RS_SCORE', r2_score(y_test,grid.predict(X_test)).round(2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardo el mejor modelo de Random Forest\n",
    "\n",
    "with open('modelos/otros/RandomForest_GridSearch_model','wb') as archivo_salida:\n",
    "    pickle.dump(grid,archivo_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Ada Boost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada_reg = AdaBoostRegressor(n_estimators=200,\n",
    "                            random_state=42)\n",
    "ada_reg.fit(X_train, y_train)\n",
    "\n",
    "predictions_ada_reg = ada_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train:  22324.34\n",
      "MAPE train:  322.0 %\n",
      "MSE train:  541326925.13\n",
      "RMSE train:  23266.43\n",
      "R2_Score train -0.94\n"
     ]
    }
   ],
   "source": [
    "MAE_ada_reg = mean_absolute_error(y_train, predictions_ada_reg)\n",
    "MAPE_ada_reg = mean_absolute_percentage_error(y_train,predictions_ada_reg)\n",
    "MSE_ada_reg = mean_squared_error(y_train,predictions_ada_reg)\n",
    "RMSE_ada_reg = np.sqrt(mean_squared_error(y_train,predictions_ada_reg))\n",
    "RS_SCORE_ada_reg = r2_score(y_train,predictions_ada_reg)\n",
    "print(\"MAE train: \", MAE_ada_reg.round(2))\n",
    "print(\"MAPE train: \",MAPE_ada_reg.round(2)*100,\"%\")\n",
    "print(\"MSE train: \", MSE_ada_reg.round(2))\n",
    "print(\"RMSE train: \", RMSE_ada_reg.round(2))\n",
    "print(\"R2_Score train\",RS_SCORE_ada_reg.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 22312.09\n",
      "test MAPE: 321.0 %\n",
      "test MSE: 549193816.56\n",
      "Test RMSE:23434.8800\n",
      "RS_SCORE -0.55\n"
     ]
    }
   ],
   "source": [
    "print(\"test MAE:\", mean_absolute_error(y_test, ada_reg.predict(X_test)).round(2))\n",
    "print(\"test MAPE:\", mean_absolute_percentage_error(y_test, ada_reg.predict(X_test)).round(2)*100, \"%\")\n",
    "print(\"test MSE:\", mean_squared_error(y_test, ada_reg.predict(X_test)).round(2))\n",
    "print(\"Test RMSE:%0.4f\"% np.sqrt(mean_squared_error(y_test, ada_reg.predict(X_test))).round(2))\n",
    "print('RS_SCORE', r2_score(y_test,ada_reg.predict(X_test)).round(2))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GridSearch Ada Boost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=AdaBoostRegressor(random_state=42),\n",
       "             param_grid={'learning_rate': range(1, 10),\n",
       "                         'n_estimators': range(1, 10)},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_par_ada = {'n_estimators': range(1,10,1),'learning_rate':range(1,10,1)}\n",
    "modelo_ada = AdaBoostRegressor(random_state=42)\n",
    "grid_ada = GridSearchCV(modelo_ada, grid_par_ada,scoring='r2',cv=5)\n",
    "grid_ada.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(learning_rate=2, n_estimators=4, random_state=42)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_ada = AdaBoostRegressor(learning_rate=2, n_estimators=4,random_state=42)\n",
    "grid_ada.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_ada_grid = grid_ada.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor estimator es AdaBoostRegressor(learning_rate=2, n_estimators=4, random_state=42)\n",
      "Los mejores parámetros son {'learning_rate': 2, 'n_estimators': 4}\n",
      "El mejor score es 0.7518552213780858\n"
     ]
    }
   ],
   "source": [
    "print(\"El mejor estimator es\",grid_ada.best_estimator_)\n",
    "print(\"Los mejores parámetros son\",grid_ada.best_params_)\n",
    "print(\"El mejor score es\",grid_ada.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train:  5171.36\n",
      "MAPE train:  61.0 %\n",
      "MSE train:  63609363.78\n",
      "RMSE train:  7975.55\n",
      "R2_Score train 0.77\n"
     ]
    }
   ],
   "source": [
    "MAE_ada_reg_grid = mean_absolute_error(y_train, predictions_ada_grid)\n",
    "MAPE_ada_reg_grid = mean_absolute_percentage_error(y_train,predictions_ada_grid)\n",
    "MSE_ada_reg_grid = mean_squared_error(y_train,predictions_ada_grid)\n",
    "RMSE_ada_reg_grid = np.sqrt(mean_squared_error(y_train,predictions_ada_grid))\n",
    "RS_SCORE_ada_reg_grid = r2_score(y_train,predictions_ada_grid)\n",
    "print(\"MAE train: \", MAE_ada_reg_grid.round(2))\n",
    "print(\"MAPE train: \",MAPE_ada_reg_grid.round(2)*100,\"%\")\n",
    "print(\"MSE train: \", MSE_ada_reg_grid.round(2))\n",
    "print(\"RMSE train: \", RMSE_ada_reg_grid.round(2))\n",
    "print(\"R2_Score train\",RS_SCORE_ada_reg_grid.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 5381.22\n",
      "test MAPE: 61.0 %\n",
      "test MSE: 87180701.39\n",
      "Test RMSE:9337.0600\n",
      "RS_SCORE 0.75\n"
     ]
    }
   ],
   "source": [
    "print(\"test MAE:\", mean_absolute_error(y_test, grid_ada.predict(X_test)).round(2))\n",
    "print(\"test MAPE:\", mean_absolute_percentage_error(y_test, grid_ada.predict(X_test)).round(2)*100, \"%\")\n",
    "print(\"test MSE:\", mean_squared_error(y_test, grid_ada.predict(X_test)).round(2))\n",
    "print(\"Test RMSE:%0.4f\"% np.sqrt(mean_squared_error(y_test, grid_ada.predict(X_test))).round(2))\n",
    "print('RS_SCORE', r2_score(y_test,grid_ada.predict(X_test)).round(2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardo el mejor modelo de Ada Boost\n",
    "\n",
    "with open('modelos/otros/AdaBoostRegressor_GridSearch_model','wb') as archivo_salida:\n",
    "    pickle.dump(grid_ada,archivo_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt = GradientBoostingRegressor(max_depth=2,\n",
    "                                 n_estimators=3, \n",
    "                                 learning_rate=1.0,\n",
    "                                 random_state=42)\n",
    "gbrt.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "predictions_gbrt = gbrt.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train:  5566.54\n",
      "MAPE train:  55.00000000000001 %\n",
      "MSE train:  76054100.98\n",
      "RMSE train:  8720.9\n",
      "R2_Score train 0.73\n"
     ]
    }
   ],
   "source": [
    "MAE_gbrt = mean_absolute_error(y_train, predictions_gbrt)\n",
    "MAPE_gbrt = mean_absolute_percentage_error(y_train,predictions_gbrt)\n",
    "MSE_gbrt = mean_squared_error(y_train,predictions_gbrt)\n",
    "RMSE_gbrt = np.sqrt(mean_squared_error(y_train,predictions_gbrt))\n",
    "RS_SCORE_gbrt = r2_score(y_train,predictions_gbrt)\n",
    "print(\"MAE train: \", MAE_gbrt.round(2))\n",
    "print(\"MAPE train: \",MAPE_gbrt.round(2)*100,\"%\")\n",
    "print(\"MSE train: \", MSE_gbrt.round(2))\n",
    "print(\"RMSE train: \", RMSE_gbrt.round(2))\n",
    "print(\"R2_Score train\",RS_SCORE_gbrt.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 5746.74\n",
      "test MAPE: 56.00000000000001 %\n",
      "test MSE: 101788663.69\n",
      "Test RMSE:10089.0400\n",
      "RS_SCORE 0.71\n"
     ]
    }
   ],
   "source": [
    "print(\"test MAE:\", mean_absolute_error(y_test, gbrt.predict(X_test)).round(2))\n",
    "print(\"test MAPE:\", mean_absolute_percentage_error(y_test, gbrt.predict(X_test)).round(2)*100, \"%\")\n",
    "print(\"test MSE:\", mean_squared_error(y_test, gbrt.predict(X_test)).round(2))\n",
    "print(\"Test RMSE:%0.4f\"% np.sqrt(mean_squared_error(y_test, gbrt.predict(X_test))).round(2))\n",
    "print('RS_SCORE', r2_score(y_test,gbrt.predict(X_test)).round(2))  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grid Search Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(estimator=GradientBoostingRegressor(learning_rate=1.0, max_depth=2,\n",
       "                                                 n_estimators=3,\n",
       "                                                 random_state=42),\n",
       "             param_grid={'learning_rate': [0.1, 0.2, 0.3],\n",
       "                         'max_depth': [2, 4, 6], 'min_samples_split': [2, 4, 6],\n",
       "                         'n_estimators': [50, 100, 150, 200]},\n",
       "             scoring='r2')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {'n_estimators': [50, 100, 150, 200],\n",
    "          'max_depth': [2, 4, 6],\n",
    "          'min_samples_split': [2, 4, 6],\n",
    "          'learning_rate': [0.1, 0.2, 0.3]}\n",
    "\n",
    "\n",
    "grid_gbrt = GridSearchCV(gbrt, params,scoring='r2')\n",
    "grid_gbrt.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El mejor estimator es GradientBoostingRegressor(learning_rate=0.2, max_depth=4, n_estimators=200,\n",
      "                          random_state=42)\n",
      "Los mejores parámetros son {'learning_rate': 0.2, 'max_depth': 4, 'min_samples_split': 2, 'n_estimators': 200}\n",
      "El mejor score es 0.9625614919287774\n"
     ]
    }
   ],
   "source": [
    "print(\"El mejor estimator es\",grid_gbrt.best_estimator_)\n",
    "print(\"Los mejores parámetros son\",grid_gbrt.best_params_)\n",
    "print(\"El mejor score es\",grid_gbrt.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbrt_grid = GradientBoostingRegressor(max_depth=4,\n",
    "                                 n_estimators=200, \n",
    "                                 learning_rate=0.2,\n",
    "                                 random_state=42,\n",
    "                                 min_samples_split=2)\n",
    "gbrt_grid.fit(X_train, y_train)\n",
    "\n",
    "predictions_gbrt_grid = gbrt_grid.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train:  808.61\n",
      "MAPE train:  6.0 %\n",
      "MSE train:  1828236.69\n",
      "RMSE train:  1352.12\n",
      "R2_Score train 0.99\n"
     ]
    }
   ],
   "source": [
    "MAE_gbrt_grid = mean_absolute_error(y_train, predictions_gbrt_grid)\n",
    "MAPE_gbrt_grid = mean_absolute_percentage_error(y_train,predictions_gbrt_grid)\n",
    "MSE_gbrt_grid = mean_squared_error(y_train,predictions_gbrt_grid)\n",
    "RMSE_gbrt_grid = np.sqrt(mean_squared_error(y_train,predictions_gbrt_grid))\n",
    "RS_SCORE_gbrt_grid = r2_score(y_train,predictions_gbrt_grid)\n",
    "print(\"MAE train: \", MAE_gbrt_grid.round(2))\n",
    "print(\"MAPE train: \",MAPE_gbrt_grid.round(2)*100,\"%\")\n",
    "print(\"MSE train: \", MSE_gbrt_grid.round(2))\n",
    "print(\"RMSE train: \", RMSE_gbrt_grid.round(2))\n",
    "print(\"R2_Score train\",RS_SCORE_gbrt_grid.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 1089.43\n",
      "test MAPE: 6.0 %\n",
      "test MSE: 14501098.59\n",
      "Test RMSE:3808.0300\n",
      "RS_SCORE 0.96\n"
     ]
    }
   ],
   "source": [
    "print(\"test MAE:\", mean_absolute_error(y_test, gbrt_grid.predict(X_test)).round(2))\n",
    "print(\"test MAPE:\", mean_absolute_percentage_error(y_test, gbrt_grid.predict(X_test)).round(2)*100, \"%\")\n",
    "print(\"test MSE:\", mean_squared_error(y_test, gbrt_grid.predict(X_test)).round(2))\n",
    "print(\"Test RMSE:%0.4f\"% np.sqrt(mean_squared_error(y_test, gbrt_grid.predict(X_test))).round(2))\n",
    "print('RS_SCORE', r2_score(y_test,gbrt_grid.predict(X_test)).round(2))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardo el mejor modelo de Gradient, que finalmente es mi modelo elegido\n",
    "\n",
    "with open('modelos/final/my_model','wb') as archivo_salida:\n",
    "    pickle.dump(gbrt_grid,archivo_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgboost.XGBRegressor(random_state=42)\n",
    "\n",
    "xgb_reg.fit(X_train, y_train)\n",
    "predictions_xgb = xgb_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = xgboost.XGBRegressor(random_state=42)\n",
    "\n",
    "xgb_reg.fit(X_train.values, y_train)\n",
    "predictions_xgb = xgb_reg.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE train:  480.94\n",
      "MAPE train:  4.0 %\n",
      "MSE train:  565255.12\n",
      "RMSE train:  751.83\n",
      "R2_Score train 1.0\n"
     ]
    }
   ],
   "source": [
    "MAE_xgb = mean_absolute_error(y_train, predictions_xgb)\n",
    "MAPE_xgb = mean_absolute_percentage_error(y_train,predictions_xgb)\n",
    "MSE_xgb = mean_squared_error(y_train,predictions_xgb)\n",
    "RMSE_xgb = np.sqrt(mean_squared_error(y_train,predictions_xgb))\n",
    "RS_SCORE_xgb = r2_score(y_train,predictions_xgb)\n",
    "print(\"MAE train: \", MAE_xgb.round(2))\n",
    "print(\"MAPE train: \",MAPE_xgb.round(2)*100,\"%\")\n",
    "print(\"MSE train: \", MSE_xgb.round(2))\n",
    "print(\"RMSE train: \", RMSE_xgb.round(2))\n",
    "print(\"R2_Score train\",RS_SCORE_xgb.round(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test MAE: 903.96\n",
      "test MAPE: 5.0 %\n",
      "test MSE: 17031170.04\n",
      "Test RMSE:4126.8800\n",
      "RS_SCORE 0.95\n"
     ]
    }
   ],
   "source": [
    "print(\"test MAE:\", mean_absolute_error(y_test, xgb_reg.predict(X_test)).round(2))\n",
    "print(\"test MAPE:\", mean_absolute_percentage_error(y_test, xgb_reg.predict(X_test)).round(2)*100, \"%\")\n",
    "print(\"test MSE:\", mean_squared_error(y_test, xgb_reg.predict(X_test)).round(2))\n",
    "print(\"Test RMSE:%0.4f\"% np.sqrt(mean_squared_error(y_test, xgb_reg.predict(X_test))).round(2))\n",
    "print('RS_SCORE', r2_score(y_test,xgb_reg.predict(X_test)).round(2)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Guardo el mejor modelo de xgb\n",
    "\n",
    "with open('model/xgb_reg','wb') as archivo_salida:\n",
    "    pickle.dump(xgb_reg,archivo_salida)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Agrupo los mejores resultados de todos los modelos probados en un dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Métrica</th>\n",
       "      <th>Linear_R</th>\n",
       "      <th>Polynomial_R</th>\n",
       "      <th>Decision_Tree_Grid</th>\n",
       "      <th>KNN</th>\n",
       "      <th>SVM_Grid</th>\n",
       "      <th>RFR_Grid</th>\n",
       "      <th>ADA_Boost_Grid</th>\n",
       "      <th>Gradient_Boosting_Grid</th>\n",
       "      <th>xgb_grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAE</td>\n",
       "      <td>4768.59</td>\n",
       "      <td>2987.31</td>\n",
       "      <td>1979.23</td>\n",
       "      <td>3236.03</td>\n",
       "      <td>4458.96</td>\n",
       "      <td>1690.11</td>\n",
       "      <td>5381.22</td>\n",
       "      <td>1089.43</td>\n",
       "      <td>903.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>52.63</td>\n",
       "      <td>35.38</td>\n",
       "      <td>9.94</td>\n",
       "      <td>19.02</td>\n",
       "      <td>40.54</td>\n",
       "      <td>8.68</td>\n",
       "      <td>61.11</td>\n",
       "      <td>6.50</td>\n",
       "      <td>4.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSE</td>\n",
       "      <td>117283074.77</td>\n",
       "      <td>25979246.74</td>\n",
       "      <td>35102027.57</td>\n",
       "      <td>55980274.91</td>\n",
       "      <td>141716795.62</td>\n",
       "      <td>22447050.25</td>\n",
       "      <td>87180701.39</td>\n",
       "      <td>14501098.59</td>\n",
       "      <td>17031170.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>10829.73</td>\n",
       "      <td>5096.98</td>\n",
       "      <td>5924.70</td>\n",
       "      <td>7482.00</td>\n",
       "      <td>11904.49</td>\n",
       "      <td>4737.83</td>\n",
       "      <td>9337.06</td>\n",
       "      <td>3808.03</td>\n",
       "      <td>4126.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R2</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.93</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Métrica     Linear_R  Polynomial_R  Decision_Tree_Grid         KNN  \\\n",
       "0     MAE      4768.59       2987.31             1979.23     3236.03   \n",
       "1    MAPE        52.63         35.38                9.94       19.02   \n",
       "2     MSE 117283074.77   25979246.74         35102027.57 55980274.91   \n",
       "3    RMSE     10829.73       5096.98             5924.70     7482.00   \n",
       "4      R2         0.67          0.93                0.90        0.84   \n",
       "\n",
       "      SVM_Grid    RFR_Grid  ADA_Boost_Grid  Gradient_Boosting_Grid    xgb_grid  \n",
       "0      4458.96     1690.11         5381.22                 1089.43      903.96  \n",
       "1        40.54        8.68           61.11                    6.50        4.54  \n",
       "2 141716795.62 22447050.25     87180701.39             14501098.59 17031170.04  \n",
       "3     11904.49     4737.83         9337.06                 3808.03     4126.88  \n",
       "4         0.60        0.94            0.75                    0.96        0.95  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resultados = {'Métrica':['MAE','MAPE','MSE','RMSE','R2'],\n",
    "            'Linear_R':[\n",
    "            mean_absolute_error(y_test, reg_mod_2.predict(X_test)),\n",
    "            mean_absolute_percentage_error(y_test, reg_mod_2.predict(X_test))*100,\n",
    "            mean_squared_error(y_test, reg_mod_2.predict(X_test)),\n",
    "            np.sqrt(mean_squared_error(y_test, reg_mod_2.predict(X_test))),\n",
    "            r2_score(y_test,reg_mod_2.predict(X_test))],\n",
    "            'Polynomial_R': [mean_absolute_error(y_test, pol_reg_test.predict(X_poly_test)),\n",
    "                  mean_absolute_percentage_error(y_test, pol_reg_test.predict(X_poly_test))*100,\n",
    "                  mean_squared_error(y_test, pol_reg_test.predict(X_poly_test)),\n",
    "                  np.sqrt(mean_squared_error(y_test, pol_reg_test.predict(X_poly_test))),\n",
    "                  r2_score(y_test,pol_reg_test.predict(X_poly_test))]\n",
    "            \n",
    "            }\n",
    "\n",
    "resultados = pd.DataFrame(resultados)\n",
    "\n",
    "resultados['Decision_Tree_Grid'] = [mean_absolute_error(y_test, grid_dtr.predict(X_test)),\n",
    "                                mean_absolute_percentage_error(y_test, grid_dtr.predict(X_test))*100,\n",
    "                                mean_squared_error(y_test, grid_dtr.predict(X_test)),\n",
    "                                np.sqrt(mean_squared_error(y_test, grid_dtr.predict(X_test))),\n",
    "                                r2_score(y_test,grid_dtr.predict(X_test))\n",
    "\n",
    "]\n",
    "\n",
    "resultados['KNN'] = [mean_absolute_error(y_test, knn.predict(X_test_scal)),\n",
    "                    mean_absolute_percentage_error(y_test, knn.predict(X_test_scal))*100,\n",
    "                    mean_squared_error(y_test, knn.predict(X_test_scal)),\n",
    "                    np.sqrt(mean_squared_error(y_test, knn.predict(X_test_scal))),\n",
    "                    r2_score(y_test,knn.predict(X_test_scal))  \n",
    "]\n",
    "\n",
    "resultados['SVM_Grid'] = [mean_absolute_error(y_test, svm_grid.predict(X_test_scal)),\n",
    "                        mean_absolute_percentage_error(y_test, svm_grid.predict(X_test_scal))*100,\n",
    "                        mean_squared_error(y_test, svm_grid.predict(X_test_scal)),\n",
    "                        np.sqrt(mean_squared_error(y_test, svm_grid.predict(X_test_scal))),\n",
    "                        r2_score(y_test,svm_grid.predict(X_test_scal))\n",
    "                        ]\n",
    "\n",
    "resultados['RFR_Grid'] = [mean_absolute_error(y_test, grid.predict(X_test)),\n",
    "                        mean_absolute_percentage_error(y_test, grid.predict(X_test))*100,\n",
    "                        mean_squared_error(y_test, grid.predict(X_test)),\n",
    "                        np.sqrt(mean_squared_error(y_test, grid.predict(X_test))),\n",
    "                        r2_score(y_test,grid.predict(X_test))\n",
    "                        ]\n",
    "\n",
    "resultados['ADA_Boost_Grid'] = [mean_absolute_error(y_test, grid_ada.predict(X_test)),\n",
    "                                mean_absolute_percentage_error(y_test, grid_ada.predict(X_test))*100,\n",
    "                                mean_squared_error(y_test, grid_ada.predict(X_test)),\n",
    "                                np.sqrt(mean_squared_error(y_test, grid_ada.predict(X_test))),\n",
    "                                r2_score(y_test,grid_ada.predict(X_test))\n",
    "                                ]\n",
    "\n",
    "resultados['Gradient_Boosting_Grid'] = [mean_absolute_error(y_test, gbrt_grid.predict(X_test)),\n",
    "                                        mean_absolute_percentage_error(y_test, gbrt_grid.predict(X_test))*100,\n",
    "                                        mean_squared_error(y_test, gbrt_grid.predict(X_test)),\n",
    "                                        np.sqrt(mean_squared_error(y_test, gbrt_grid.predict(X_test))),\n",
    "                                        r2_score(y_test,gbrt_grid.predict(X_test))]\n",
    "\n",
    "resultados['xgb_grid'] = [\n",
    "                    mean_absolute_error(y_test, xgb_reg.predict(X_test)),\n",
    "                    mean_absolute_percentage_error(y_test, xgb_reg.predict(X_test))*100,\n",
    "                    mean_squared_error(y_test, xgb_reg.predict(X_test)),\n",
    "                    np.sqrt(mean_squared_error(y_test, xgb_reg.predict(X_test))),\n",
    "                    r2_score(y_test,xgb_reg.predict(X_test))\n",
    "]\n",
    "\n",
    "\n",
    "\n",
    "resultados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analizando con otra métrica más (MAX_ERROR), para elegir entre el modelo Gradient Boosting y XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Métrica</th>\n",
       "      <th>Gradient_Boosting_Grid</th>\n",
       "      <th>xgb_grid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MAE</td>\n",
       "      <td>1089.43</td>\n",
       "      <td>903.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>MAPE</td>\n",
       "      <td>6.50</td>\n",
       "      <td>4.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MSE</td>\n",
       "      <td>14501098.59</td>\n",
       "      <td>17031170.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RMSE</td>\n",
       "      <td>3808.03</td>\n",
       "      <td>4126.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>R2</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>MAX_ERROR</td>\n",
       "      <td>189550.43</td>\n",
       "      <td>194864.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Métrica  Gradient_Boosting_Grid    xgb_grid\n",
       "0        MAE                 1089.43      903.96\n",
       "1       MAPE                    6.50        4.54\n",
       "2        MSE             14501098.59 17031170.04\n",
       "3       RMSE                 3808.03     4126.88\n",
       "4         R2                    0.96        0.95\n",
       "5  MAX_ERROR               189550.43   194864.88"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_gradientvsxgb = {'Métrica': ['MAE','MAPE','MSE','RMSE','R2','MAX_ERROR'],\n",
    "                'Gradient_Boosting_Grid':[mean_absolute_error(y_test, gbrt_grid.predict(X_test)),\n",
    "                                        mean_absolute_percentage_error(y_test, gbrt_grid.predict(X_test))*100,\n",
    "                                        mean_squared_error(y_test, gbrt_grid.predict(X_test)),\n",
    "                                        np.sqrt(mean_squared_error(y_test, gbrt_grid.predict(X_test))),\n",
    "                                        r2_score(y_test,gbrt_grid.predict(X_test)),\n",
    "                                        max_error(y_test,gbrt_grid.predict(X_test))\n",
    "\n",
    "                    \n",
    "                ]}\n",
    "r_gradientvsxgb = pd.DataFrame(r_gradientvsxgb)\n",
    "r_gradientvsxgb['xgb_grid'] = [\n",
    "                    mean_absolute_error(y_test, xgb_reg.predict(X_test)),\n",
    "                    mean_absolute_percentage_error(y_test, xgb_reg.predict(X_test))*100,\n",
    "                    mean_squared_error(y_test, xgb_reg.predict(X_test)),\n",
    "                    np.sqrt(mean_squared_error(y_test, xgb_reg.predict(X_test))),\n",
    "                    r2_score(y_test,xgb_reg.predict(X_test)),\n",
    "                    max_error(y_test,xgb_reg.predict(X_test))\n",
    "                    ]\n",
    "r_gradientvsxgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Tras analizar ambas métricas con un parámetro más, decido quedarme con Gradient Boosting, ya que los errores máximos son menores. En este caso que nuestro modelo trata de la predicción de precios de venta de coches de segunnda, por lo cual se podría implementar en portales de compra ventas de coches, lo más interesante es que el error máximo sea el menor posible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardo el mejor modelo, listo para poner en producción\n",
    "\n",
    "with open('model/final/my_model','wb') as archivo_salida:\n",
    "    pickle.dump(gbrt_grid,archivo_salida)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('model/my_model', 'rb') as archivo_entrada:\n",
    "    model = pickle.load(archivo_entrada)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([16438.63852937, 12330.58108617,  8541.64338995, ...,\n",
       "       22590.45365441,  4745.19829956,  1590.82146535])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(X_train)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b89b7659d6d1f95ccdfc29511c5ccd7e0d849fb1c891534338821144de18a3b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
